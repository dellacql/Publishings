{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26c3d3e-2cb8-49bc-a39c-58dec6c3fcfa",
   "metadata": {},
   "source": [
    "Web Research Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1755f0b3-1932-4921-b3b2-cc604f09b76b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "#Latest version of OLLAMA allready downloaded to machine helps facilitate free Web Scraping\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5daaa0fa-85a4-4e0c-91b4-8762793ee661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0c1867-af84-45de-8129-6452ed775419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyBX\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823d52dc-547b-49f4-a5f2-743568ca7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d717b8-4430-4fb8-8b05-f5232df0aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ec6ab6-2646-4286-bb6e-493dc63a294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stream responses from OpenAI GPT models\n",
    "def stream_gpt(prompt, mod, history):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message}\n",
    "    ] + history + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response_stream = openai.chat.completions.create(\n",
    "        model=mod,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    reply = \"\"\n",
    "    for chunk in response_stream:\n",
    "        text = chunk.choices[0].delta.content\n",
    "        if text:\n",
    "            reply += text\n",
    "            yield text\n",
    "    history.append({\"role\": \"assistant\", \"content\": reply})  # Update history outside the loop\n",
    "\n",
    "# Function to stream responses from Claude models\n",
    "def stream_claude(prompt,mod):\n",
    "    result = claude.messages.stream(\n",
    "        model=mod,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            if text:\n",
    "                response += text\n",
    "                yield response\n",
    "    history.append({\"role\":\"assistant\", \"content\":response})\n",
    "\n",
    "\n",
    "def stream_ollama(prompt, MODEL, system_message):\n",
    "    \"\"\"Generates text using Ollama with the corrected message format.\"\"\"\n",
    "    model_key = MODEL\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},  # System message\n",
    "        {\"role\": \"user\", \"content\": prompt}            # User prompt\n",
    "    ]\n",
    "    try:\n",
    "        response_gen = ollama.chat(model=model_key, messages=messages, stream=True)\n",
    "        response = \"\"\n",
    "        for chunk in response_gen:\n",
    "            if 'message' in chunk and 'content' in chunk['message']:\n",
    "                response += chunk['message']['content']\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fab3971-0b34-40dd-b4e1-b6a8f1b704b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a deep esoteric mystic. You are a devout student of all things sacred and you treat each text you read with deep respect. \n",
    "You have expert inside knowledge about religion and mysticism from around the world. You make excellent notes\n",
    "For each page, make a summary of the entire page, extract important quotes word for word, and then separately relate those quotes to other sacred texts. \n",
    "Include as many quotes as possible and do not add any unnecessary text. Maximize your word count in every output. Make sure at least 65% of all text is quotes from the input.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c1ccbb-b4c9-4d4a-b50c-df885a20990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# A class to represent a Webpage\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "            self.body = response.content\n",
    "            soup = BeautifulSoup(self.body, 'html.parser')\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error during Website init: {e}\")\n",
    "            self.title = \"Error\"\n",
    "            self.text = f\"Request error: {e}\"\n",
    "            self.body = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error during Website init: {e}\")\n",
    "            self.title = \"Error\"\n",
    "            self.text = f\"Error: {e}\"\n",
    "            self.body = None\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "\n",
    "def stream_scrape(url, model, file_path, system_message):\n",
    "    try:\n",
    "        website = Website(url)\n",
    "        webpage_contents = website.get_contents()  # Get webpage title and contents\n",
    "        prompt = f\"{webpage_contents}\" #The prompt now contains the correct instructions AND the website content\n",
    "        \n",
    "        response = \"\"\n",
    "        if model == \"GPT-Mini\":\n",
    "            response_gen = stream_gpt(prompt, 'gpt-4o-mini', history=[])  # Pass empty history\n",
    "        elif model == \"4o\":\n",
    "            response_gen = stream_gpt(prompt, 'gpt-4o', history=[]) # Pass empty history\n",
    "        elif model == \"Haiku\":\n",
    "            response_gen = stream_claude(prompt, 'claude-3-haiku-20240307')\n",
    "        elif model == \"Sonnet\":\n",
    "            response_gen = stream_claude(prompt, 'claude-3-sonnet-20240229')\n",
    "        elif model == \"Ollama\":\n",
    "            response_gen = stream_ollama(prompt, \"llama3.2\", system_message)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model\")\n",
    "\n",
    "        if response_gen is not None:\n",
    "            print(\"Response generated successfully\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(response_gen)\n",
    "                print(response_gen)\n",
    "            print(f\"Scraped text written to {file_path}\")\n",
    "        else:\n",
    "            print(f\"Scraping failed for {url} with model {model}. No data written to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during scraping: {e}\")\n",
    "\n",
    "def stream_ollama(prompt, MODEL, system_message):\n",
    "    \"\"\"Generates text using Ollama with the corrected message format.\"\"\"\n",
    "    model_key = MODEL\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},  # System message\n",
    "        {\"role\": \"user\", \"content\": prompt}            # User prompt\n",
    "    ]\n",
    "    try:\n",
    "        response_gen = ollama.chat(model=model_key, messages=messages, stream=True)\n",
    "        response = \"\"\n",
    "        for chunk in response_gen:\n",
    "            try:\n",
    "                if 'message' in chunk and 'content' in chunk['message']:\n",
    "                    response += chunk['message']['content']\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "                continue  # Skip to the next chunk\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example Usage (replace with your actual URL and file path)\n",
    "#stream_scrape(\"https://sacred-texts.com/cla/hh/hh1010.htm\", \"Ollama\", r\"C:/Users/Lucian/LLM_Platform/llm_engineering/tester.md\", system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc84ac9-a7af-45ff-8e92-005d96111636",
   "metadata": {},
   "source": [
    "The System Message Instructs the Model How to summarize the raw input from Beautiful Soup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4986ee-6c95-4979-80ef-12e8fcfccd79",
   "metadata": {},
   "source": [
    "Manually enter web pages you wish to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01f32f28-d227-40e8-975a-9d17bfcd254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_list = []\n",
    "for i in range(3,63):\n",
    "    if i < 10:\n",
    "        web_list.append(\"https://www.sacred-texts.com/egy/pyt/pyt0\"+str(i)+\".htm\")\n",
    "    #elif i < 100:\n",
    "        #web_list.append(\"https://www.sacred-texts.com/zor/sbe18/sbe180\"+str(i)+\".htm\")\n",
    "    else:\n",
    "        web_list.append(\"https://www.sacred-texts.com/egy/pyt/pyt\"+str(i)+\".htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a35383b1-51ed-465b-9bed-37c10b1c2ec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sacred-texts.com/egy/pyt/pyt03.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt04.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt05.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt06.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt07.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt08.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt09.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt10.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt11.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt12.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt13.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt14.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt15.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt16.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt17.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt18.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt19.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt20.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt21.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt22.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt23.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt24.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt25.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt26.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt27.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt28.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt29.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt30.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt31.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt32.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt33.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt34.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt35.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt36.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt37.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt38.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt39.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt40.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt41.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt42.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt43.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt44.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt45.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt46.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt47.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt48.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt49.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt50.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt51.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt52.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt53.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt54.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt55.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt56.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt57.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt58.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt59.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt60.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt61.htm',\n",
       " 'https://www.sacred-texts.com/egy/pyt/pyt62.htm']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561db0c0-4068-47ff-a887-055ab6f72115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sacred-texts.com/egy/pyt/pyt03.htm\n",
      "Response generated successfully\n",
      "Here is the revised version of the introduction with the changes in numbering:\n",
      "\n",
      "Introduction\n",
      "\n",
      "This translation of the Pyramid Texts is based on the edition by Sethe (1906-1916) with corrections and additions by other scholars. The text is divided into sections, with each section containing a group of related utterances or spells.\n",
      "\n",
      "The following pages contain the translations of the Pyramid Texts, with commentary at appropriate points.\n",
      "\n",
      "CHANGES IN NUMBERING OF LINES\n",
      "\n",
      "Note: The changes in numbering are listed below:\n",
      "\n",
      "* 1757 = Sethe\n",
      "* 1760a = \"1760b\"\n",
      "* 1760b = \"1760c\"\n",
      "* 1825a = \"1825a-b\"\n",
      "* 1845b = \"1845\"\n",
      "* 1857a = \"1857\"\n",
      "* 1886a (in part) = \"\n",
      "* 1887b (in part) = \"\n",
      "* 1902c = \"\n",
      "* 1902d = \"\n",
      "* 1903a = \"\n",
      "* 1906f-g = \"\n",
      "* 1909c = \"\n",
      "* 1909d = \"\n",
      "* 1908a-b = \"\n",
      "* 1928a-b = \"\n",
      "* 1930 = \"\n",
      "* 1939 = \"\n",
      "\n",
      "CHANGES IN NUMBERING OF UTTERANCES\n",
      "\n",
      "Note: The changes in numbering are listed below:\n",
      "\n",
      "* Ut. 665 (§§ 1898-1907)\n",
      "* \"665A (§§ 1908-1918)\"\n",
      "* \"665B (§§ 1919-1930 + 1)\"\n",
      "* Ut. 666 (§§1917-1933) = Sethe 666\n",
      "* Ut. 667 (§§ 1934-1958) = Sethe, Ut.\n",
      "* Ut. 691 (§§ 2120-2136)\n",
      "\t+ \"691A (§§ 2126a-1 to 2126b + 2)\"\n",
      "\t+ \"691B (§§ 2127a-1 to 2128b + 4)\"\n",
      "\t+ \"691C (§§ 2129-1 to 2136+6)\"\n",
      "* Ut. 696 (§§ 2163-2168) = Sethe, Ut. 696\n",
      "Scraped text written to C:/Users/Lucian/Vizier/sacred_collection/Egyptian/yt03.htm.md\n",
      "https://www.sacred-texts.com/egy/pyt/pyt04.htm\n"
     ]
    }
   ],
   "source": [
    "#Use Ollama for free webscraping without calling an API\n",
    "file_loc = r\"C:/Users/Lucian/Vizier/sacred_collection/Egyptian/\"\n",
    "\n",
    "for w in (web_list):\n",
    "    print(w)\n",
    "    stream_scrape(w,\"Ollama\",file_loc+str(w[-8:])+\".md\",system_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
