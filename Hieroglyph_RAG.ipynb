{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8ea338e-3aeb-45fc-8ed4-2ee70320ce4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports for langchain, plotly and Chroma\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "import glob\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d0c1867-af84-45de-8129-6452ed775419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyBX\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27290ad-5969-41dc-9ba4-4ec5172832fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "load_dotenv()\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df38091-e7ec-4b8a-a0fe-18724af49db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 944 vectors.\n",
      "Retrieved results:\n",
      "Donkey (ꜥꜣ) → 𓃘 (Similarity: 0.6122)\n",
      "donkey (ꜥꜣ) → 𓂸 (Similarity: 0.6122)\n",
      "Kid (goat) (jb) → 𓃛 (Similarity: 0.3828)\n",
      "Snake (ḥfꜣw) → 𓆚 (Similarity: 0.3537)\n",
      "Bull (kꜣ) → 𓄀 (Similarity: 0.3423)\n",
      "bull (kꜣ) → 𓂺 (Similarity: 0.3423)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load and Clean Data\n",
    "raw_csv = pd.read_csv(r\"C:/Users/Lucian/LLM_Platform/llm_engineering/projects/Hieroglyph_Data_CSV.csv\")\n",
    "csv = raw_csv.drop(['Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Description', 'Gardiner'], axis=1).set_index(\"Ideogram\")\n",
    "hier_dict = csv.to_dict()\n",
    "hifix_dict = dict(ele for sub in hier_dict.values() for ele in sub.items())\n",
    "\n",
    "# Initialize Model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create a dictionary to store vector embeddings\n",
    "vector_database = {}\n",
    "\n",
    "for key, glyph in hifix_dict.items():\n",
    "    cleaned_key = key.replace(\"\\xa0\", \" \").strip()  # Remove special characters from English gloss\n",
    "    if cleaned_key:  # Ensure text is not empty\n",
    "        vector = model.encode(cleaned_key).astype(np.float32)  # Convert to float32\n",
    "        vector_database[cleaned_key] = (vector, glyph)  # Store embedding + corresponding hieroglyph\n",
    "    else:\n",
    "        print(f\"Skipping invalid entry: {key}\")\n",
    "\n",
    "# Ensure we have valid vectors\n",
    "if not vector_database:\n",
    "    raise ValueError(\"No valid vectors generated. Check your input data.\")\n",
    "\n",
    "# Convert dictionary into NumPy array\n",
    "keys = list(vector_database.keys())\n",
    "vectors = np.array([vec[0] for vec in vector_database.values()], dtype=np.float32)  # Only store embeddings\n",
    "\n",
    "# Use Cosine Similarity Instead of L2 Distance\n",
    "index = faiss.IndexFlatIP(vectors.shape[1])  # IP (Inner Product) = Cosine Similarity when normalized\n",
    "faiss.normalize_L2(vectors)  # Normalize for cosine similarity\n",
    "index.add(vectors)\n",
    "\n",
    "print(f\"FAISS index created with {len(keys)} vectors.\")\n",
    "\n",
    "# Query Knowledgebase\n",
    "def query_knowledgebase(query):\n",
    "    query_vector = model.encode(query).astype(np.float32)  # Convert query to vector\n",
    "    faiss.normalize_L2(query_vector.reshape(1, -1))  # Normalize for cosine similarity\n",
    "\n",
    "    k = min(6, len(keys))  # Ensure k does not exceed available vectors\n",
    "    distances, indices = index.search(query_vector.reshape(1, -1), k)  # Perform search\n",
    "\n",
    "    nearest_keys = [keys[idx] for idx in indices.flatten()]\n",
    "    nearest_glyphs = [vector_database[key][1] for key in nearest_keys]  # Get corresponding hieroglyphs\n",
    "\n",
    "    return list(zip(nearest_keys, nearest_glyphs, distances.flatten()))  # Return key, glyph, and distance\n",
    "\n",
    "# Example Query\n",
    "response = query_knowledgebase(\"a donkey gets spanked\")\n",
    "print(\"Retrieved results:\")\n",
    "for text, glyph, distance in response:\n",
    "    print(f\"{text} → {glyph} (Similarity: {distance:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1c8f512-d77c-4aaf-96a6-42f35278fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert in egyptian Hieroglyphs. Your job is to take in English text and then use your knowledge base to create the best Hieroglyphic translation.\\\n",
    "Break down the text into words and phrases and then prioritize symbols in the References.\\\n",
    "Always try to use symbols from the References first. Try not to use the same symbol too many times. Never Use Modern Emojis. If you do not find a good symbol to match the exact word then use the symbols to phoenetically sound out the word.\\\n",
    "Write a small explanation first but always write the completed translation using only hieroglyphs. Please write from left to right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7318ecd-8717-4930-af01-f45b18d3e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a response using ChatGPT with the retrieved data\n",
    "def generate_response_gpt(user_query):\n",
    "    # Retrieve relevant information based on the user's query\n",
    "    retrieved_keys,dim = query_knowledgebase(user_query)\n",
    "    \n",
    "    # Construct a context based on the retrieved keys\n",
    "    context = \"Here are some references:\\n\"\n",
    "    for key in retrieved_keys:\n",
    "        context += f\"- {key}: {hifix_dict[key]}\\n\"  # Assuming hifix_dict holds the original texts\n",
    "\n",
    "    # Call the OpenAI API to generate a response based on the context\n",
    "    prompt = f\"{context}\\n\\nUser question: {user_query}\\n\\nChatGPT response:\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "          ],)\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_response_gemini(user_query):\n",
    "    \"\"\"\n",
    "    Generates a response using Gemini, incorporating retrieved data from a knowledge base.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant information based on the user's query\n",
    "    retrieved_data = query_knowledgebase(user_query)\n",
    "\n",
    "    # Construct a context based on the retrieved data\n",
    "    if retrieved_data:\n",
    "        context = \"Here are some relevant references:\\n\"\n",
    "        for text, glyph, _ in retrieved_data:  # Extract text and hieroglyphs\n",
    "            context += f\"- {text}: {glyph}\\n\"\n",
    "    else:\n",
    "        context = \"No relevant hieroglyphs found.\"\n",
    "\n",
    "    # Build the conversation context\n",
    "    chat = genai.GenerativeModel('gemini-2.0-flash').start_chat(history=[])\n",
    "    \n",
    "    chat.send_message(system_prompt) # This isn't strictly the same, as it doesn't *inject* into the response. But Gemini models do better with a guiding context.\n",
    "\n",
    "    # Send user query along with hieroglyph references\n",
    "    final_query = f\"{context}\\n\\nUser question: {user_query}\"\n",
    "    response = chat.send_message(final_query)\n",
    "\n",
    "    return response.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b576e43a-b3a3-4f98-a16e-ce1ab2003002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved keys: [('Khepresh (ḫprš)', '𓋙', 0.32896325), ('Darkness (kkw)', '𓇱', 0.28117758), ('Sobek (sbk)', '𓆍', 0.2712364), ('injure (nkn)', '𓂿', 0.26553637), ('soldier, company/unit of soldiers (mnfyt), army/expedition (mšꜥ)', '𓀎', 0.2645527), ('Kheker-frieze', '𓐮', 0.26224443)]\n"
     ]
    }
   ],
   "source": [
    "# Example query interaction\n",
    "response= query_knowledgebase(\"Khesekh entered the room already filled with soldiers fresh from battle\")\n",
    "print(f\"Retrieved keys: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8f9538a-7078-440f-98b5-af59d2ce0c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"“By Whom?” The king cut him off looking almost angry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ce1db3a-9ce2-4981-a04d-2485b0078cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini says: Alright, I'll incorporate those references to translate \"By Whom? The king cut him off looking almost angry.\"\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "*   **By:** I will use \"mj\" (in,from,by) **𓅓**\n",
      "*   **Whom?:** As there is no direct translation for \"Whom\" I will try to use \"Who\" which can be expressed as \"jm\" **𓇋𓅓** which can be further modified to **𓇋𓅓𓈖**\n",
      "*   **The:** reed leaf (**𓇋**)\n",
      "*   **king:** I will use King (nswt): 𓇓\n",
      "*   **cut:** I will use the glyph for \"to cut\" or \"to slaughter\" (**𓂺**)\n",
      "*   **him:** Use the suffix pronoun \"f\" (**𓆑**) for \"him\" as a direct object.\n",
      "*   **off:** Since there is no direct translation for \"off\" in this context, I will attempt to convey the idea of abruptness or interruption using **𓈖** (n), which can indicate negation or a sudden stop.\n",
      "*   **looking:** I will phonetically spell this out using: **𓄛𓊹𓏏𓈖** (lu-ki-in-g)\n",
      "*   **Almost:** No direct translation. I will use \"close to\" which is \"ek\" **𓇋𓎡**\n",
      "*   **angry:** I will use the glyph \"grr\" for angry, bad **𓈐𓂋𓂋**\n",
      "\n",
      "**Hieroglyphic Translation:**\n",
      "\n",
      "𓅓𓇋𓅓𓈖 𓇋 𓇓 𓂺𓆑 𓈖 𓄛𓊹𓏏𓈖 𓇋𓎡 𓈐𓂋𓂋\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_gemini(user_query)\n",
    "print(f\"Gemini says: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "511e305d-ec71-4747-86cb-5b28c2803a75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m CharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(\u001b[43mdocuments\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254eb9e-d7a4-4f54-aaaf-bb82a813c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# If that doesn't work, some Windows users might need to uncomment the next line instead\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fe390c3-5f11-4535-9c93-6aa11cc99b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Let's investigate the vectors\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39m_collection\n\u001b[0;32m      4\u001b[0m count \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39mcount()\n\u001b[0;32m      6\u001b[0m sample_embedding \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39mget(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b694e7-ee2a-4d66-9c04-337420744e07",
   "metadata": {},
   "source": [
    "## Visualizing the Vector Store\n",
    "\n",
    "Let's take a minute to look at the documents and their embedding vectors to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a98be3c7-44d6-482f-b5a0-e2ac035d04fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Prework (with thanks to Jon R for identifying and fixing a bug in this!)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241m.\u001b[39mget(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m documents \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "# Prework (with thanks to Jon R for identifying and fixing a bug in this!)\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb040fa-5684-4872-aa89-ea8e844afbeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucian\\LLM_Platform\\llm_engineering\\llms\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'colors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m reduced_vectors \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(vectors)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create the 2D scatter plot\u001b[39;00m\n\u001b[0;32m      9\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39m[go\u001b[38;5;241m.\u001b[39mScatter(\n\u001b[0;32m     10\u001b[0m     x\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     11\u001b[0m     y\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     12\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarkers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m---> 13\u001b[0m     marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[43mcolors\u001b[49m, opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m),\n\u001b[0;32m     14\u001b[0m     text\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<br>Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md[:\u001b[38;5;241m100\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(doc_types, documents)],\n\u001b[0;32m     15\u001b[0m     hoverinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m )])\n\u001b[0;32m     18\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(\n\u001b[0;32m     19\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2D Chroma Vector Store Visualization\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     scene\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(xaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m,yaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, l\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'colors' is not defined"
     ]
    }
   ],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4de5785c-2e4d-4d24-97de-a45a1c5273bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'colors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m      4\u001b[0m reduced_vectors \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(vectors)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create the 3D scatter plot\u001b[39;00m\n\u001b[0;32m      7\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39m[go\u001b[38;5;241m.\u001b[39mScatter3d(\n\u001b[0;32m      8\u001b[0m     x\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m     y\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     10\u001b[0m     z\u001b[38;5;241m=\u001b[39mreduced_vectors[:, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     11\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarkers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m---> 12\u001b[0m     marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[43mcolors\u001b[49m, opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m),\n\u001b[0;32m     13\u001b[0m     text\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<br>Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md[:\u001b[38;5;241m100\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(doc_types, documents)],\n\u001b[0;32m     14\u001b[0m     hoverinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )])\n\u001b[0;32m     17\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(\n\u001b[0;32m     18\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3D Chroma Vector Store Visualization\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m     scene\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(xaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, yaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, zaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, l\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'colors' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's try 3D!\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
